{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import os\n",
    "from materials_io.utils.interface import get_available_parsers, get_parser\n",
    "import multiprocessing as mp\n",
    "\n",
    "def run_parser(file_parser):\n",
    "    \"\"\"Helper function for multiprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "    file_parser (parser, file): 2-tuple containing a parser name\n",
    "    to use for parsing and a file(s) to parse.\n",
    "    \n",
    "    Returns:\n",
    "    metadata {file_name: {parser_name: metadata_dict}}: Returns\n",
    "    dictionary of metadata with parser and file names included.\n",
    "    \"\"\"\n",
    "    parser = get_parser(file_parser[0])\n",
    "    file = file_parser[1]\n",
    "    \n",
    "    try:\n",
    "        metadata = {file: {file_parser[0]: parser.parse(file)}}\n",
    "        return metadata\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def run_all_parsers_mp(directory, exclude_parsers=None, processes=mp.cpu_count()):\n",
    "    \"\"\"Runs all parsers on a directory but uses multiprocessing.\n",
    "    \n",
    "    Parameters:\n",
    "    directory (str): Directory to run parsers on.\n",
    "    exclude_parsers (list): List of parsers to not run.\n",
    "    \n",
    "    Returns:\n",
    "    file_metadata (file_name: {parser_name: metadata_dict}}):\n",
    "    List of dictionaries of metadata as returned by run_parser.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    parsers = get_available_parsers()\n",
    "    file_metadata = []\n",
    "    task_queue = []\n",
    "    \n",
    "    if exclude_parsers is not None:\n",
    "        parsers = list(set(parsers.keys()).difference(exclude_parsers))\n",
    "    \n",
    "    print(\"starting...\")\n",
    "    \n",
    "    for parser in parsers:\n",
    "        parser_obj = get_parser(parser)\n",
    "        \n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            # Generate the full paths\n",
    "            dirs = [os.path.join(root, d) for d in dirs]\n",
    "            files = [os.path.join(root, f) for f in files]\n",
    "\n",
    "            for group in parser_obj.group(files,dirs):\n",
    "                task_queue.append((parser, group))\n",
    "    \n",
    "    print(\"It took {} seconds to generate the queue. {} jobs in queue\".format(time.time() - start_time,\n",
    "                                                                              len(task_queue)))\n",
    "    print(\"starting job processing...\")\n",
    "    \n",
    "    pools = mp.Pool(processes)\n",
    "    \n",
    "    for metadata in pools.imap_unordered(run_parser, task_queue):\n",
    "        file_metadata.append(metadata)\n",
    "        if (len(file_metadata) % 1000) == 0:\n",
    "            print(\"{} out of {} files processed\".format(len(file_metadata), len(task_queue)))\n",
    "            print(\"{} seconds have passed\\n\".format(time.time() - start_time))\n",
    "    \n",
    "    pools.close()\n",
    "    pools.join()\n",
    "    \n",
    "    file_metadata = [metadata for metadata in file_metadata if metadata is not None]\n",
    "    \n",
    "    print(\"Finished in {} seconds\".format(time.time() - start_time))\n",
    "    print(\"{} number of metadata\".format(len(file_metadata)))\n",
    "    return file_metadata\n",
    "\n",
    "def matio_label_gen(directory, label_file=None, exclude_parsers=None):\n",
    "    \"\"\"Generates file metadata using run_all_parsers_mp\n",
    "    and then writes file names and parser names to a .csv for\n",
    "    successfully extracted metadata.\n",
    "    \n",
    "    Parameters:\n",
    "    directory (str): Directory of files to write labels for.\n",
    "    label_file (str): Name of .csv to write labels to.\n",
    "    exclude_parsers (list): List of parsers to not run.\n",
    "    \"\"\"\n",
    "    file_row = []\n",
    "    \n",
    "    if label_file is None:\n",
    "        label_file = os.path.basename(directory) + \".csv\"\n",
    "    \n",
    "    file_metadata = run_all_parsers_mp(directory, exclude_parsers=exclude_parsers)\n",
    "    \n",
    "    for metadata in file_metadata:\n",
    "        file_path = list(metadata.keys())[0]\n",
    "        file_label = list(metadata[file_path].keys())[0]\n",
    "        \n",
    "        if isinstance(file_path, list):\n",
    "            for path in file_path:\n",
    "                file_row.append([path, os.path.getsize(path), file_label])\n",
    "        else:\n",
    "            file_row.append([file_path[0], os.path.getsize(file_path[0]), file_label])\n",
    "    \n",
    "    with open(label_file, 'w', newline='') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerow([\"path\", \"size\", \"file_label\"])\n",
    "        \n",
    "        for row in file_row:\n",
    "            csv_writer.writerow(row)\n",
    "    \n",
    "    print(\"Done writing labels\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dft']\n",
      "starting...\n",
      "dft\n",
      "It took 0.0006668567657470703 seconds to generate the queue. 0 jobs in queue\n",
      "starting job processing...\n",
      "Finished in 0.20463156700134277 seconds\n",
      "0 number of metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_all_parsers_mp(''\n",
    "                                , exclude_parsers=['generic', 'noop', 'csv', 'image', 'em', 'crystal', 'ase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:hyperspy.api:The ipywidgets GUI elements are not available, probably because the hyperspy_gui_ipywidgets package is not installed.\n",
      "WARNING:hyperspy.api:The traitsui GUI elements are not available, probably because the hyperspy_gui_traitsui package is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ase': {'description': 'Parse information from atomistic simulation input files using ASE.', 'version': '0.0.1', 'class': 'materials_io.ase:AseParser'}, 'crystal': {'description': 'Parse information about a crystal structure', 'version': '0.0.1', 'class': 'materials_io.crystal_structure:CrystalStructureParser'}, 'csv': {'description': 'Reads comma-separated value (CSV) files', 'version': '0.0.1', 'class': 'materials_io.csv:CSVParser'}, 'dft': {'description': 'Extract data from Density Functional Theory calculation results', 'version': '0.0.1', 'class': 'materials_io.dft:DFTParser'}, 'em': {'description': 'Parse metadata specific to electron microscopy', 'version': '0.0.1', 'class': 'materials_io.electron_microscopy:ElectronMicroscopyParser'}, 'generic': {'description': 'Gathers basic file information', 'version': '0.0.1', 'class': 'materials_io.file:GenericFileParser'}, 'image': {'description': 'Retrieves basic information about an image', 'version': '0.0.1', 'class': 'materials_io.image:ImageParser'}, 'noop': {'description': 'Determine whether files exist, used for debugging', 'version': '0.0.1', 'class': 'materials_io.testing:NOOPParser'}}\n"
     ]
    }
   ],
   "source": [
    "print(get_available_parsers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
